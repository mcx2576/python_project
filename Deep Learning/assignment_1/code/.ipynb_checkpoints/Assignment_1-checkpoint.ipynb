{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cifar10_utils\n",
    "cifar10 = cifar10_utils.get_cifar10('cifar10/cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = cifar10['train'].next_batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = cifar10['test'].images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  27.28926086,   28.8596344 ,   33.94955444, ...,   10.16941833,\n",
       "          15.09375763,   -4.38185883],\n",
       "       [ 104.28926086,  100.8596344 ,  100.94955444, ...,   64.16941833,\n",
       "          77.09375763,   84.61814117],\n",
       "       [  27.28926086,   27.8596344 ,    7.94955444, ..., -105.83058167,\n",
       "        -110.90624237, -107.38185883],\n",
       "       ..., \n",
       "       [-110.71073914, -111.1403656 , -116.05044556, ...,  -63.83058167,\n",
       "         -60.90624237,  -67.38185883],\n",
       "       [-105.71073914, -115.1403656 , -108.05044556, ...,  -33.83058167,\n",
       "         -32.90624237,  -34.38185883],\n",
       "       [ -57.71073914,  -32.1403656 ,  -32.05044556, ...,  -19.83058167,\n",
       "         -55.90624237,  -88.38185883]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.reshape(x_t.shape[0],3*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b407e9e45641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "x,y = cifar10.test.images, cifar10.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10['test'].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cifar10['train'].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.values>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10['test'].labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3, 32, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, targets):\n",
    "  \"\"\"\n",
    "  Computes the prediction accuracy, i.e. the average of correct predictions\n",
    "  of the network.\n",
    "  \n",
    "  Args:\n",
    "    predictions: 2D float array of size [batch_size, n_classes]\n",
    "    labels: 2D int array of size [batch_size, n_classes]\n",
    "            with one-hot encoding. Ground truth labels for\n",
    "            each sample in the batch\n",
    "  Returns:\n",
    "    accuracy: scalar float, the accuracy of predictions,\n",
    "              i.e. the average correct predictions over the whole batch\n",
    "  \n",
    "  TODO:\n",
    "  Implement accuracy computation.\n",
    "  \"\"\"\n",
    "\n",
    "  ########################\n",
    "  # PUT YOUR CODE HERE  #\n",
    "  #######################\n",
    "  accuracy = np.zeros((predictions.shape[0],1))\n",
    "  for i in range(predictions.shape[0]):\n",
    "      a=0\n",
    "      for j in range(predictions.shape[1]):\n",
    "          if predictions[i][j]== targets[i][j]:\n",
    "              a+=1\n",
    "          else:\n",
    "              a=a+0\n",
    "      accuracy[i]=a/predictions.shape[1]\n",
    "  accuracy=np.average(accuracy)\n",
    "\n",
    "  #raise NotImplementedError\n",
    "  ########################\n",
    "  # END OF YOUR CODE    #\n",
    "  #######################\n",
    "\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([[0,0,0,1,0],[0,1,0,1,0]])\n",
    "targets = np.array([[0,1,0,1,0],[0,1,0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for training\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "from mlp_numpy import MLP\n",
    "from modules import CrossEntropyModule\n",
    "import cifar10_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default constants\n",
    "DNN_HIDDEN_UNITS_DEFAULT = '100'\n",
    "LEARNING_RATE_DEFAULT = 2e-3\n",
    "MAX_STEPS_DEFAULT = 1500\n",
    "BATCH_SIZE_DEFAULT = 200\n",
    "EVAL_FREQ_DEFAULT = 100\n",
    "\n",
    "# Directory in which cifar data is saved\n",
    "DATA_DIR_DEFAULT = './cifar10/cifar-10-batches-py'\n",
    "\n",
    "FLAGS = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_freq : 100\n",
      "learning_rate : 0.002\n",
      "dnn_hidden_units : 100\n",
      "batch_size : 200\n",
      "data_dir : ./cifar10/cifar-10-batches-py\n",
      "max_steps : 1500\n",
      "dnn_hidden_units[100]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-59ba35b854d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-59ba35b854d6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;31m# Run the training operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-59ba35b854d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mn_inputs_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0mOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/uvadlc_practicals_2018-master/assignment_1/code/mlp_numpy.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_inputs, n_hidden, n_classes)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mLinearModule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "  \"\"\"\n",
    "  Performs training and evaluation of MLP model. \n",
    "\n",
    "  TODO:\n",
    "  Implement training and evaluation of MLP model. Evaluate your model on the whole test set each eval_freq iterations.\n",
    "  \"\"\"\n",
    "\n",
    "  ### DO NOT CHANGE SEEDS!\n",
    "  # Set the random seeds for reproducibility\n",
    "  np.random.seed(42)\n",
    "\n",
    "  ## Prepare all functions\n",
    "  # Get number of units in each hidden layer specified in the string such as 100,100\n",
    "  if FLAGS.dnn_hidden_units:\n",
    "    dnn_hidden_units = FLAGS.dnn_hidden_units.split(\",\")\n",
    "    dnn_hidden_units = [int(dnn_hidden_unit_) for dnn_hidden_unit_ in dnn_hidden_units]\n",
    "  else:\n",
    "    dnn_hidden_units = []\n",
    "\n",
    "  ########################\n",
    "  # PUT YOUR CODE HERE  #\n",
    "  #######################\n",
    "  \n",
    "  # Using parameters from the inputs\n",
    "  Learning_rate = FLAGS.learning_rate\n",
    "  max_steps = FLAGS.max_steps\n",
    "  batch_size = FLAGS.batch_size\n",
    "  eval_freq = FLAGS.eval_freq  \n",
    "  \n",
    "\n",
    "  # Get data from directory\n",
    "  cifar10 = cifar10_utils.get_cifar10(DATA_DIR_DEFAULT)\n",
    "  \n",
    "  # Set up batch size\n",
    "  x,y = cifar10['train'].next_batch(batch_size)\n",
    "  # Get test data\n",
    "  x_t,y_t = cifar10['test'].images, cifar10['test'].labels\n",
    "  print(\"dnn_hidden_units\" + str(dnn_hidden_units))\n",
    "  print(type(dnn_hidden_units))\n",
    "  n_hidden_node = dnn_hidden_units\n",
    "  n_inputs_size = 3*3*32 \n",
    "  n_classes = 10\n",
    "  mlp = MLP(n_inputs_size, n_hidden_node, n_classes)\n",
    "  Out = mlp.forward(x)\n",
    "\n",
    "  # Calculate cross entropu value\n",
    "  CM = CrossEntropyModule(Out)\n",
    "  # Evaluate the results\n",
    "  accuracy_list = []\n",
    "  loss = []\n",
    "\n",
    "  a = accuracy(Out, y)\n",
    "  print(\"accuracy rate\" + str(a))\n",
    "  accuracy_list.append(a)\n",
    "  # Start training\n",
    "  \n",
    "  raise NotImplementedError\n",
    "  ########################\n",
    "  # END OF YOUR CODE    #\n",
    "  #######################\n",
    "def print_flags():\n",
    "  \"\"\"\n",
    "  Prints all entries in FLAGS variable.\n",
    "  \"\"\"\n",
    "  for key, value in vars(FLAGS).items():\n",
    "    print(key + ' : ' + str(value))\n",
    "\n",
    "def main():\n",
    "  \"\"\"\n",
    "  Main function\n",
    "  \"\"\"\n",
    "  # Print all Flags to confirm parameter settings\n",
    "  print_flags()\n",
    "\n",
    "  if not os.path.exists(FLAGS.data_dir):\n",
    "    os.makedirs(FLAGS.data_dir)\n",
    "\n",
    "  # Run the training operation\n",
    "  train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # Command line arguments\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--dnn_hidden_units', type = str, default = DNN_HIDDEN_UNITS_DEFAULT,\n",
    "                      help='Comma separated list of number of units in each hidden layer')\n",
    "  parser.add_argument('--learning_rate', type = float, default = LEARNING_RATE_DEFAULT,\n",
    "                      help='Learning rate')\n",
    "  parser.add_argument('--max_steps', type = int, default = MAX_STEPS_DEFAULT,\n",
    "                      help='Number of steps to run trainer.')\n",
    "  parser.add_argument('--batch_size', type = int, default = BATCH_SIZE_DEFAULT,\n",
    "                      help='Batch size to run trainer.')\n",
    "  parser.add_argument('--eval_freq', type=int, default=EVAL_FREQ_DEFAULT,\n",
    "                        help='Frequency of evaluation on the test set')\n",
    "  parser.add_argument('--data_dir', type = str, default = DATA_DIR_DEFAULT,\n",
    "                      help='Directory for storing input data')\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
