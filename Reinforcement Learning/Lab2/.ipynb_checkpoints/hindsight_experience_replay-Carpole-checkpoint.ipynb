{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "from torch.autograd import Variable \n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer\n",
    "\n",
    "EPS = float(np.finfo(np.float32).eps)\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.envs.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "    time.sleep(0.05)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Q-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(8, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.l3 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        value=self.l2(F.relu(self.l1(x)))\n",
    "        value=self.l3(F.relu(self.l2(value)))\n",
    "      #  print(value.shape)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=env.reset()\n",
    "obs, reward, done, _ = env.step(env.action_space.sample())\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class ReplayMemory:\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        if len(self.memory)<self.capacity:\n",
    "            self.memory.append(transition)\n",
    "        else:\n",
    "            del self.memory[0]\n",
    "            self.memory.append(transition)\n",
    "            \n",
    "    ## The transition consists of (state, action, reward, next_state, goal)\n",
    "\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        sample=[]\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.randint(len(self.memory))\n",
    "            sample.append(self.memory[index])\n",
    "    ## Should we sample with the probability of an expisode or not???\n",
    "        return sample\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_action(model, state, epsilon):\n",
    "    with torch.no_grad():\n",
    "        s = torch.from_numpy(state)\n",
    "        s = s.type(torch.FloatTensor)\n",
    "        Q = model(s).numpy()\n",
    "        policy = np.ones([env.action_space.n])\n",
    "        policy = policy*epsilon\n",
    "        policy[Q.argmax()] = 1 - epsilon\n",
    "      #  print(policy)\n",
    "        action = int(np.random.choice(env.action_space.n, 1, p=policy))\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(it):\n",
    "    epsilon = max(1-(1-0.05)/1000*it, 0.05)\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_q_val(model, state, action):\n",
    "    # YOUR CODE HERE\n",
    "   # state_goal = np.concatenate((state,goal), axis=-1)\n",
    "    Q = model(state)\n",
    "   # selected_index=action.reshape(64)\n",
    "\n",
    "    Q_value = torch.gather(Q, 1, torch.tensor(action).reshape(64,1))\n",
    "    \n",
    "   # print(Q_value)\n",
    "    return Q_value\n",
    "   # raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "def compute_target(model, reward, next_state, done, discount_factor):\n",
    "    # done is a boolean (vector) that indicates if next_state is terminal (episode is done)\n",
    "    # YOUR CODE HERE\n",
    "    target=torch.zeros(len(reward))\n",
    "    for i in range(len(reward)):\n",
    "        if done[i] == False:\n",
    "            max_next_state_q = max(model(next_state[i]))\n",
    "            ind_target = reward[i] + discount_factor*max_next_state_q\n",
    "            target[i] = ind_target\n",
    "        else:\n",
    "            target[i]\n",
    "   # raise NotImplementedError()\n",
    "    target = target.reshape(len(reward),1)\n",
    "    return target\n",
    "\n",
    "def train(eval_model, target_model, optimizer, batch, discount_factor):\n",
    "    # DO NOT MODIFY THIS FUNCTION\n",
    "    \n",
    "    # don't learn without some decent experience\n",
    "  #  if len(memory) < batch_size:\n",
    "  #      return None\n",
    "\n",
    "    # random transition batch is taken from experience replay memory\n",
    "   # transitions = memory.sample(batch_size)\n",
    "    \n",
    "    # transition is a list of 4-tuples, instead we want 4 vectors (as torch.Tensor's)\n",
    "    state, action, reward, next_state, done = zip(*batch)\n",
    "    \n",
    "    # convert to PyTorch and define types\n",
    "    state = torch.tensor(state, dtype=torch.float)\n",
    "    action = torch.tensor(action, dtype=torch.int64)  # Need 64 bit to use them as index\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float)\n",
    "    reward = torch.tensor(reward, dtype=torch.float)\n",
    "    done = torch.tensor(done, dtype=torch.uint8)  # Boolean\n",
    "    \n",
    "    # compute the q value\n",
    "    q_val = compute_q_val(eval_model, state, action)\n",
    "    \n",
    "    with torch.enable_grad():  \n",
    "        target = compute_target(target_model, reward, next_state, done, discount_factor)\n",
    "       # print(target)\n",
    "        target = Variable(target, requires_grad=False)\n",
    "    # loss is measured from error between current and newly expected Q values\n",
    "    loss = F.smooth_l1_loss(q_val, target)\n",
    "\n",
    "    # backpropagation of loss to Neural Network (PyTorch magic)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episodes(train, eval_dqn, target_dqn, memory, env, num_episodes, batch_size, discount_factor, learn_rate):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), learn_rate)\n",
    "   # Number of updates for the DQN\n",
    "    num_updates = 0\n",
    "    \n",
    "    global_steps = 0  # Count the steps (do not reset at episode start, to compute epsilon)\n",
    "    episode_durations = []  #\n",
    "    G=[]\n",
    "    success = 0\n",
    "    for i in tqdm(range(num_episodes)):\n",
    "        state = env.reset()\n",
    "        #if len(G)==0:\n",
    "        goal = np.array([0.5,np.random.uniform(0,0.07)])\n",
    "        #else:\n",
    "           # goal = G[np.random.choice(len(G))]\n",
    "        \n",
    "        state = np.concatenate((state, goal), axis=-1)\n",
    "        done = False\n",
    "        duration = 0\n",
    "        experience=[]\n",
    "        env.render()\n",
    "        while done == False:\n",
    "            duration +=1 \n",
    "            epsilon = get_epsilon(global_steps)\n",
    "            action = select_action(model, state, epsilon)\n",
    "            s_next, reward, done, _ = env.step(action)\n",
    "            if np.absolute(s_next[1]-goal[0]) < 0.05:\n",
    "                reward = 0\n",
    "                done = True\n",
    "            else:\n",
    "                reward = -1\n",
    "                \n",
    "            env.render()\n",
    "            \n",
    "            s_next = np.concatenate((s_next, goal), axis=-1)\n",
    "            memory.push((state, action, reward, s_next, done))\n",
    "            \n",
    "            experience.append((state, action, reward, s_next, done))\n",
    "                                                                                                                   \n",
    "          #  state = s_next\n",
    "            \n",
    "            \n",
    "       #     loss = train(model, memory, optimizer, batch_size, discount_factor)\n",
    "            \n",
    "            if len(memory.memory) > batch_size:\n",
    "                minibatch = memory.sample(batch_size)\n",
    "                train(eval_dqn, target_dqn, optimizer, minibatch, discount_factor)\n",
    "                num_updates = num_updates + 1\n",
    "\n",
    "            \n",
    "            if done == True:\n",
    "                # Update target network\n",
    "                target_dqn.load_state_dict(eval_dqn.state_dict())\n",
    "                break\n",
    "            else:\n",
    "                state = s_next\n",
    "                global_steps+=1\n",
    "            \n",
    "        \n",
    "        c_state,__,__, s_next_goal,__ = experience[-1]\n",
    "        if np.absolute(s_next_goal[0]-0.5) <0.05:\n",
    "            success +=1\n",
    "        \n",
    "        if (np.absolute(s_next_goal[0]-goal[0])) > 0.05: #and (s_next_goal[0]> -0.5):\n",
    "            new_goal = s_next_goal[:2]\n",
    "            G.append(new_goal)\n",
    "            \n",
    "            for transition in experience:\n",
    "                state_old_goal,action,__, next_state_old_goal,done = transition\n",
    "                if np.absolute(state_old_goal[0]-new_goal[0]) > 0.05:\n",
    "                    reward = -1\n",
    "                else:\n",
    "                    reward = 0\n",
    "                    done = True\n",
    "                state = np.concatenate((state_old_goal[:2], new_goal))\n",
    "                next_state = np.concatenate((next_state_old_goal[:2], new_goal))\n",
    "                memory.push((state, action, reward, next_state, done))\n",
    "        \n",
    "        episode_durations.append(duration)\n",
    "        # YOUR CODE HERE\n",
    "     #   raise NotImplementedError()\n",
    "    return episode_durations, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/200 [00:03<10:57,  3.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2/200 [00:06<10:56,  3.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 3/200 [00:09<10:54,  3.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 4/200 [00:13<10:52,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▎         | 5/200 [00:16<10:49,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 6/200 [00:20<10:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 7/200 [00:23<10:43,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 8/200 [00:26<10:40,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 9/200 [00:30<10:37,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 10/200 [00:33<10:33,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 11/200 [00:36<10:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 12/200 [00:40<10:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 13/200 [00:43<10:24,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 14/200 [00:46<10:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 15/200 [00:50<10:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 16/200 [00:53<10:14,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 17/200 [00:56<10:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 18/200 [01:00<10:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 19/200 [01:03<10:04,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 20/200 [01:06<10:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 21/200 [01:10<09:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 22/200 [01:13<09:54,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 23/200 [01:16<09:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 24/200 [01:20<09:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 25/200 [01:23<09:44,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 26/200 [01:26<09:40,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 27/200 [01:30<09:38,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 28/200 [01:33<09:34,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 29/200 [01:36<09:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 30/200 [01:40<09:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 31/200 [01:43<09:24,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 32/200 [01:46<09:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 33/200 [01:50<09:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 34/200 [01:53<09:14,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 35/200 [01:56<09:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 36/200 [02:00<09:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 37/200 [02:03<09:04,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 38/200 [02:06<09:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 39/200 [02:10<08:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 40/200 [02:13<08:54,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 41/200 [02:16<08:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 42/200 [02:20<08:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 43/200 [02:23<08:44,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 44/200 [02:26<08:40,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▎       | 45/200 [02:30<08:37,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 46/200 [02:33<08:34,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 47/200 [02:36<08:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 48/200 [02:40<08:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 49/200 [02:43<08:24,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 50/200 [02:46<08:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 51/200 [02:50<08:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 52/200 [02:53<08:14,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 53/200 [02:56<08:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 54/200 [03:00<08:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 55/200 [03:03<08:04,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 56/200 [03:06<08:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 57/200 [03:10<07:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 58/200 [03:13<07:54,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 59/200 [03:16<07:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 60/200 [03:20<07:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 61/200 [03:23<07:44,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 62/200 [03:26<07:40,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 63/200 [03:30<07:37,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 64/200 [03:33<07:34,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▎      | 65/200 [03:36<07:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 66/200 [03:40<07:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 67/200 [03:43<07:24,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 68/200 [03:46<07:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 69/200 [03:50<07:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 70/200 [03:53<07:13,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 71/200 [03:56<07:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 72/200 [04:00<07:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 73/200 [04:03<07:03,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 74/200 [04:07<07:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 75/200 [04:10<06:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 76/200 [04:13<06:54,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 77/200 [04:17<06:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 78/200 [04:20<06:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 79/200 [04:23<06:43,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 80/200 [04:27<06:41,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 81/200 [04:30<06:36,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 82/200 [04:33<06:33,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 83/200 [04:37<06:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 84/200 [04:40<06:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▎     | 85/200 [04:43<06:23,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 86/200 [04:47<06:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 87/200 [04:50<06:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 88/200 [04:53<06:13,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 89/200 [04:57<06:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 90/200 [05:00<06:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 91/200 [05:03<06:03,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 92/200 [05:07<06:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 93/200 [05:10<05:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 94/200 [05:13<05:53,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 95/200 [05:17<05:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 96/200 [05:20<05:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 97/200 [05:23<05:43,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 98/200 [05:27<05:40,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 99/200 [05:30<05:37,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 100/200 [05:33<05:33,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 101/200 [05:37<05:30,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 102/200 [05:40<05:27,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 103/200 [05:43<05:23,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 104/200 [05:47<05:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▎    | 105/200 [05:50<05:17,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 106/200 [05:53<05:13,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 107/200 [05:57<05:10,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 108/200 [06:00<05:07,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 109/200 [06:03<05:03,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 110/200 [06:07<05:00,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 111/200 [06:10<04:57,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 112/200 [06:13<04:53,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 113/200 [06:17<04:50,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 114/200 [06:20<04:47,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▊    | 115/200 [06:23<04:43,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 116/200 [06:27<04:40,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 117/200 [06:30<04:37,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 118/200 [06:33<04:33,  3.34s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Let's run it!\n",
    "num_episodes = 200\n",
    "batch_size = 64\n",
    "discount_factor = 0.8\n",
    "learn_rate = 1e-3\n",
    "memory = ReplayMemory(40000)\n",
    "num_hidden = 20\n",
    "seed = 42  # This is not randomly chosen\n",
    "\n",
    "# We will seed the algorithm (before initializing QNetwork!) for reproducability\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "\n",
    "\n",
    "# MC = MOUNTAINCAR\n",
    "\n",
    "# Create DQNs\n",
    "\n",
    "eval_dqn = QNetwork(num_hidden)\n",
    "target_dqn = QNetwork(num_hidden)\n",
    "\n",
    "\n",
    "\n",
    "##model = QNetwork(num_hidden)\n",
    "\n",
    "episode_durations, success = run_episodes(train, eval_dqn,target_dqn, memory, env, num_episodes, batch_size, discount_factor, learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Episode durations per episode')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def smooth(x, N):\n",
    " #   cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "  #  return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.plot(episode_durations)\n",
    "plt.title('Episode durations per episode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
